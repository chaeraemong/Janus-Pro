{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48b4cf94-004b-48a2-ae03-8e041614f7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version is above 3.10, patching the collections module.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/janus-pro-lora/lib/python3.10/site-packages/transformers/models/auto/image_processing_auto.py:590: FutureWarning: The image_processor_class argument is deprecated and will be removed in v4.42. Please use `slow_image_processor_class`, or `fast_image_processor_class` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d8451d5a8ba4cf2af0a33bf7cf3896e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Some kwargs in processor config are unused and will not have any effect: image_tag, pad_tag, add_special_token, num_image_tokens, ignore_id, image_end_tag, mask_prompt, image_start_tag, sft_format. \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "090ec5aebf684590b14e04e183fca62b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FileUpload(value=(), accept='image/*', description='Upload'), Text(value='', description='Quest…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 导入必要的库\n",
    "import torch\n",
    "from transformers import AutoConfig, AutoModelForCausalLM\n",
    "from janus.models import MultiModalityCausalLM, VLChatProcessor\n",
    "from janus.utils.io import load_pil_images\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "from ipywidgets import FileUpload, Text, Button, HBox, VBox, Output\n",
    "import os\n",
    "from io import BytesIO\n",
    "\n",
    "# 加载模型和处理器\n",
    "model_path = \"/root/autodl-tmp/deepseek-janus-pro-lora/20250127\"  \n",
    "config = AutoConfig.from_pretrained(model_path)\n",
    "language_config = config.language_config\n",
    "language_config._attn_implementation = 'eager'\n",
    "vl_gpt = AutoModelForCausalLM.from_pretrained(model_path,\n",
    "                                             language_config=language_config,\n",
    "                                             trust_remote_code=True)\n",
    "if torch.cuda.is_available():\n",
    "    vl_gpt = vl_gpt.to(torch.bfloat16).cuda()\n",
    "else:\n",
    "    vl_gpt = vl_gpt.to(torch.float16)\n",
    "\n",
    "vl_chat_processor = VLChatProcessor.from_pretrained(model_path)\n",
    "tokenizer = vl_chat_processor.tokenizer\n",
    "cuda_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "@torch.inference_mode()\n",
    "def multimodal_understanding(image, question, top_p=0.95, temperature=0.1):\n",
    "    # 清空 CUDA 缓存\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    \n",
    "    # 将字节流转换为 PIL 图像\n",
    "    try:\n",
    "        pil_image = Image.open(BytesIO(image)).convert(\"RGB\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image: {e}\")\n",
    "        return \"无法加载图片，请检查图片格式是否正确。\"\n",
    "    \n",
    "    # 构建对话模板\n",
    "    conversation = [\n",
    "        {\n",
    "            \"role\": \"<|User|>\",\n",
    "            \"content\": f\"<image_placeholder>\\n{question}\",\n",
    "            \"images\": [\"image_placeholder\"],  # 这里只是一个占位符，实际图片通过 `images` 参数传递\n",
    "        },\n",
    "        {\"role\": \"<|Assistant|>\", \"content\": \"\"},\n",
    "    ]\n",
    "    \n",
    "    # 使用处理器准备输入\n",
    "    try:\n",
    "        prepare_inputs = vl_chat_processor(\n",
    "            conversations=conversation, images=[pil_image], force_batchify=True\n",
    "        ).to(cuda_device, dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float16)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing inputs: {e}\")\n",
    "        return \"输入处理失败，请检查模型和处理器配置。\"\n",
    "    \n",
    "    # 获取嵌入表示\n",
    "    inputs_embeds = vl_gpt.prepare_inputs_embeds(**prepare_inputs)\n",
    "    \n",
    "    # 生成回答\n",
    "    try:\n",
    "        outputs = vl_gpt.language_model.generate(\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            attention_mask=prepare_inputs.attention_mask,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            bos_token_id=tokenizer.bos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            max_new_tokens=512,\n",
    "            do_sample=False if temperature == 0 else True,\n",
    "            use_cache=True,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating response: {e}\")\n",
    "        return \"生成回答失败，请检查模型配置。\"\n",
    "    \n",
    "    # 解码生成的回答\n",
    "    answer = tokenizer.decode(outputs[0].cpu().tolist(), skip_special_tokens=True)\n",
    "    return answer\n",
    "\n",
    "# Notebook 界面\n",
    "upload = FileUpload(accept=\"image/*\", multiple=False)  # 图片上传\n",
    "question_input = Text(description=\"Question\")  # 文字提示输入框\n",
    "output = Output()  # 输出区域\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        if upload.value:\n",
    "            # 打印 upload.value 的内容，以便调试\n",
    "            print(\"upload.value:\", upload.value)\n",
    "            # 获取上传的图片字节流\n",
    "            try:\n",
    "                # 尝试从 upload.value 中提取字节流\n",
    "                image_bytes = upload.value[0]['content']\n",
    "            except (KeyError, TypeError) as e:\n",
    "                # 如果失败，打印错误信息\n",
    "                print(\"Error extracting image bytes:\", e)\n",
    "                return\n",
    "            question = question_input.value  # 获取输入的问题\n",
    "            answer = multimodal_understanding(image_bytes, question)\n",
    "            display(HTML(f\"<h3>Response:</h3><p>{answer}</p>\"))\n",
    "\n",
    "button = Button(description=\"Chat\")\n",
    "button.on_click(on_button_clicked)\n",
    "\n",
    "# 显示界面\n",
    "display(VBox([upload, question_input, button, output]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2938cd6a-af14-4f52-9797-447c923f65a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (janus-pro-lora)",
   "language": "python",
   "name": "janus-pro-lora"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
