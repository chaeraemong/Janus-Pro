{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b4cf94-004b-48a2-ae03-8e041614f7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import torch\n",
    "from transformers import AutoConfig, AutoModelForCausalLM\n",
    "from janus.models import MultiModalityCausalLM, VLChatProcessor\n",
    "from janus.utils.io import load_pil_images\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "from ipywidgets import FileUpload, Text, Button, HBox, VBox, Output\n",
    "import os\n",
    "from io import BytesIO\n",
    "\n",
    "# 加载模型和处理器\n",
    "model_path = \"/root/autodl-tmp/Janus-1/20250127\"  \n",
    "config = AutoConfig.from_pretrained(model_path)\n",
    "language_config = config.language_config\n",
    "language_config._attn_implementation = 'eager'\n",
    "vl_gpt = AutoModelForCausalLM.from_pretrained(model_path,\n",
    "                                             language_config=language_config,\n",
    "                                             trust_remote_code=True)\n",
    "if torch.cuda.is_available():\n",
    "    vl_gpt = vl_gpt.to(torch.bfloat16).cuda()\n",
    "else:\n",
    "    vl_gpt = vl_gpt.to(torch.float16)\n",
    "\n",
    "vl_chat_processor = VLChatProcessor.from_pretrained(model_path)\n",
    "tokenizer = vl_chat_processor.tokenizer\n",
    "cuda_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "@torch.inference_mode()\n",
    "def multimodal_understanding(image, question, top_p=0.95, temperature=0.1):\n",
    "    # 清空 CUDA 缓存\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    \n",
    "    # 将字节流转换为 PIL 图像\n",
    "    try:\n",
    "        pil_image = Image.open(BytesIO(image)).convert(\"RGB\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image: {e}\")\n",
    "        return \"无法加载图片，请检查图片格式是否正确。\"\n",
    "    \n",
    "    # 构建对话模板\n",
    "    conversation = [\n",
    "        {\n",
    "            \"role\": \"<|User|>\",\n",
    "            \"content\": f\"<image_placeholder>\\n{question}\",\n",
    "            \"images\": [\"image_placeholder\"],  # 这里只是一个占位符，实际图片通过 `images` 参数传递\n",
    "        },\n",
    "        {\"role\": \"<|Assistant|>\", \"content\": \"\"},\n",
    "    ]\n",
    "    \n",
    "    # 使用处理器准备输入\n",
    "    try:\n",
    "        prepare_inputs = vl_chat_processor(\n",
    "            conversations=conversation, images=[pil_image], force_batchify=True\n",
    "        ).to(cuda_device, dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float16)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing inputs: {e}\")\n",
    "        return \"输入处理失败，请检查模型和处理器配置。\"\n",
    "    \n",
    "    # 获取嵌入表示\n",
    "    inputs_embeds = vl_gpt.prepare_inputs_embeds(**prepare_inputs)\n",
    "    \n",
    "    # 生成回答\n",
    "    try:\n",
    "        outputs = vl_gpt.language_model.generate(\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            attention_mask=prepare_inputs.attention_mask,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            bos_token_id=tokenizer.bos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            max_new_tokens=512,\n",
    "            do_sample=False if temperature == 0 else True,\n",
    "            use_cache=True,\n",
    "            temperature=temperature,\n",
    "            top_p=top_p,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating response: {e}\")\n",
    "        return \"生成回答失败，请检查模型配置。\"\n",
    "    \n",
    "    # 解码生成的回答\n",
    "    answer = tokenizer.decode(outputs[0].cpu().tolist(), skip_special_tokens=True)\n",
    "    return answer\n",
    "\n",
    "# Notebook 界面\n",
    "upload = FileUpload(accept=\"image/*\", multiple=False)  # 图片上传\n",
    "question_input = Text(description=\"Question\")  # 文字提示输入框\n",
    "output = Output()  # 输出区域\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    with output:\n",
    "        output.clear_output()\n",
    "        if upload.value:\n",
    "            # 打印 upload.value 的内容，以便调试\n",
    "            print(\"upload.value:\", upload.value)\n",
    "            # 获取上传的图片字节流\n",
    "            try:\n",
    "                # 尝试从 upload.value 中提取字节流\n",
    "                image_bytes = upload.value[0]['content']\n",
    "            except (KeyError, TypeError) as e:\n",
    "                # 如果失败，打印错误信息\n",
    "                print(\"Error extracting image bytes:\", e)\n",
    "                return\n",
    "            question = question_input.value  # 获取输入的问题\n",
    "            answer = multimodal_understanding(image_bytes, question)\n",
    "            display(HTML(f\"<h3>Response:</h3><p>{answer}</p>\"))\n",
    "\n",
    "button = Button(description=\"Chat\")\n",
    "button.on_click(on_button_clicked)\n",
    "\n",
    "# 显示界面\n",
    "display(VBox([upload, question_input, button, output]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
